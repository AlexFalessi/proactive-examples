<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.8"
     xsi:schemaLocation="urn:proactive:jobdescriptor:3.8 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.8/schedulerjob.xsd"
    name="Split_Data" projectName="3. Data Preprocessing"
    priority="normal"
    onTaskError="continueJobExecution"
     maxNumberOfExecution="2">
  <description>
    <![CDATA[ Divide the data into two sets. ]]>
  </description>
        <genericInformation>
    <info name="bucketName" value="machine-learning"/>
    <info name="pca.action.icon" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/icons/split_data.png"/>
    <info name="Documentation" value="http://activeeon.com/resources/automated-machine-learning-activeeon.pdf"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Split_Data">
      <description>
        <![CDATA[ TRAIN_SIZE: float/int
If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split. If int, represents the absolute number of train samples. ]]>
      </description>
      <variables>
        <variable name="TRAIN_SIZE" value="0.7" inherited="false" />
      </variables>
      <genericInformation>
        <info name="pca.action.icon" value="https://s3.eu-west-2.amazonaws.com/activeeon-public/icons/split_data.png"/>
      </genericInformation>
      <forkEnvironment javaHome="${PA_SCHEDULER_HOME}/jre" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3' 
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
print("BEGIN Split_Data")

from sklearn import model_selection
import pandas as pd

IS_LABELED = variables.get("IS_LABELED_DATA")

TRAIN_SPLIT = float(variables.get("TRAIN_SIZE"))
test_size = 1 - TRAIN_SPLIT

DATAFRAME_JSON = variables.get("DATAFRAME_JSON")
dataframe = pd.read_json(DATAFRAME_JSON, orient='split')
COLUMNS_NAME_JSON = variables.get("COLUMNS_NAME_JSON")
columns_name_df = pd.read_json(COLUMNS_NAME_JSON,typ='series')
columns_name = columns_name_df.values
columns_number = len(columns_name)
indice = dataframe.index.values
data = dataframe.values

if IS_LABELED:
  label = dataframe.values[:,columns_number-1]
  
  data_train, data_test, label_train, label_test, idx_train, idx_test = model_selection.train_test_split(data, label, indice, test_size=test_size)
  data_train_df = pd.DataFrame(data=data_train, columns=columns_name[0:columns_number-1], index=idx_train)
  label_train_df = pd.DataFrame(data=label_train, columns=[columns_name[columns_number-1]])
  data_test_df = pd.DataFrame(data=data_test, columns=columns_name[0:columns_number-1], index=idx_test)   
  label_test_df = pd.DataFrame(data=label_test, columns=[columns_name[columns_number-1]])  
  
  variables.put("DATA_TRAIN_DF_JSON", data_train_df.to_json(orient='split'))
  variables.put("DATA_TEST_DF_JSON", data_test_df.to_json(orient='split'))
  variables.put("LABEL_TRAIN_DF_JSON", label_train_df.to_json(orient='split'))
  variables.put("LABEL_TEST_DF_JSON", label_test_df.to_json(orient='split'))
  print("END Split_Data")
    
elif IS_LABELED == 'False' or IS_LABELED == None:
  data_train, data_test, idx_train, idx_test = model_selection.train_test_split(data,indice, test_size=test_size)
  data_train_df = pd.DataFrame(data=data_train, columns=columns_name, index=idx_train)
  data_test_df = pd.DataFrame(data=data_test, columns=columns_name, index=idx_test)
  
  variables.put("DATA_TRAIN_DF_JSON", data_train_df.to_json(orient='split'))
  variables.put("DATA_TEST_DF_JSON", data_test_df.to_json(orient='split'))
  print("END Split_Data")

else:
  print('The data could not be split, please check ypur ML pipeline')
]]>
          </code>
        </script>
      </scriptExecutable>
      <controlFlow block="none"></controlFlow>
    </task>
  </taskFlow>
</job>