<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.10"
     xsi:schemaLocation="urn:proactive:jobdescriptor:3.10 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.10/schedulerjob.xsd"
    name="Azure_Entity_Linking" projectName="1. Azure Cognitive Services"
    priority="normal"
    onTaskError="continueJobExecution"
     maxNumberOfExecution="2"
>
  <description>
    <![CDATA[ This is an implementation of wrapper of the Microsoft Azure Cognitive Entity Linking Service. ]]>
  </description>
  <genericInformation>
    <info name="Documentation" value="https://docs.microsoft.com/en-us/azure/cognitive-services/entitylinking/home"/>
    <info name="pca.action.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/entity_linking_api.png"/>
  </genericInformation>
  <taskFlow>
    <task name="Azure_Entity_Linking">
      <description>
        <![CDATA[ This task wraps the Entity Linking API of Microsoft which is a natural language processing tool to analyze text and link named-entities to relevant entries in a knowledge base.
The task requires this third-party credential : $ENTITY_LINKING_API_KEY which provides access to this API. Please refer to the User documentation to learn how to add third-party credentials. ]]>
      </description>
      <variables>
        <variable name="TEXT" value="" inherited="false" />
        <variable name="OUTPUT_FORMAT" value="HTML" inherited="false" model="PA:LIST(CSV, HTML)"/>
        <variable name="SELECTION" value="" inherited="false" />
        <variable name="OFFSET" value="-1" inherited="false" model="PA:Integer"/>
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/entity_linking_api.png"/>
      </genericInformation>
      <forkEnvironment javaHome="${PA_SCHEDULER_HOME}/jre" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
#Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
# Prepare Docker parameters 
containerName = 'activeeon/dlm3' 
dockerRunCommand =  'docker run ' 
dockerParameters = '--rm ' 
# Prepare ProActive home volume 
paHomeHost = variables.get("PA_SCHEDULER_HOME") 
paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
# Prepare working directory (For Dataspaces and serialized task file) 
workspaceHost = localspace 
workspaceContainer = localspace 
workspaceVolume = '-v '+localspace +':'+localspace+' ' 
# Prepare container working directory 
containerWorkingDirectory = '-w '+workspaceContainer+' ' 
# Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <pre>
        <script>
          <code language="bash">
            <![CDATA[

]]>
          </code>
        </script>
      </pre>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import requests
import json
import urllib
from pprint import pprint
import pandas as pd


# You can customize the api server location
api_location="westus"

# READ TASK VARIABLES
if 'variables' in locals():
    if variables.get("TEXT") is not None:
        TEXT = variables.get("TEXT")
    if variables.get("SELECTION") is not None:
        SELECTION = variables.get("SELECTION")
    if variables.get("OFFSET") is not None:
        OFFSET = int(variables.get("OFFSET"))
    if variables.get("OUTPUT_FORMAT") is not None:
        OUTPUT_FORMAT = variables.get("OUTPUT_FORMAT")
    # Provide a valid subscription API token
    if credentials.get("ENTITY_LINKING_API_KEY") is not None:
        subscription_key = credentials.get("ENTITY_LINKING_API_KEY")
    else:
        print("You first need to add your Azure Cognitive Services API key to the third party credentials")
        sys.exit(1)

# Send API request
headers   = {
    "Ocp-Apim-Subscription-Key": subscription_key,
    'Content-Type': 'text/plain'
}

params=None

# If SELECTION is not defined, skip
if SELECTION is not None and len(SELECTION)>0:
    params = urllib.parse.urlencode({'selection': SELECTION,'offset': OFFSET})

# Congitive Services - Text Analytics API URL:
service_url = "https://{0}.api.cognitive.microsoft.com/entitylinking/v1.0/link".format(api_location)

if params is not None:
    print(params)
    print(SELECTION)
    response  = requests.post(service_url, headers=headers, data=TEXT.encode('utf-8'), params=params)
else:
    response  = requests.post(service_url, headers=headers, data=TEXT.encode('utf-8'))

# Get a JSON response
api_results = response.json()

# Print the results
#pprint(api_results)

print("BEGIN Export_Results")

OUTPUT_DATA = api_results["entities"]

variables.put('ENTITY_LINKING_OUTPUT', api_results)

# Convert the results into HTML
table = []
for document in OUTPUT_DATA:
    name= document["name"]
    wiki_id= document["wikipediaId"]
    score= document["score"]
    res = ", ".join(["{0}".format(match["entries"]) for match in document["matches"]])
    table.append("<tr><td>{0}</td><td>{1}</td><td>{2}</td><td>[{3}]</td>".format(name, wiki_id, score,res))
    
html = ("<table><tr><th>name</th><th>wikipediaId</th><th>score</th><th>matches</th></tr>{0}</table>").format("\n".join(table))
html_container="""
            
            
            
            
            
            
            <!DOCTYPE html>
            <html>
              <head>
                <meta charset="UTF-8">
                  <meta name="description" content="Entity Linking API Results">
                  </head>
                  <body>{0}</body></html>""".format(html)


if OUTPUT_DATA != None and 'resultMetadata' in locals(): 
    #dataframe = pd.read_json(json.dumps(OUTPUT_DATA), orient='table', encoding='utf-8')
    dataframe=pd.read_html(html_container,header=0, encoding='utf-8')[0]
    
    if OUTPUT_FORMAT == 'CSV':
        result = dataframe.to_csv(index=False)
        resultMetadata.put("file.extension", ".csv")
        resultMetadata.put("file.name", "result.csv")
        resultMetadata.put("content.type", "text/csv")
    elif OUTPUT_FORMAT == 'HTML':
        result = dataframe.to_html(index=False)
        resultMetadata.put("file.extension", ".html")
        resultMetadata.put("file.name", "result.html")
        resultMetadata.put("content.type", "text/html")
        resultMetadata.put("charset", "UTF-8")
    print("END Export_Results")  
else:
    print('It is not possible to export the data')
]]>
                </code>
              </script>
            </scriptExecutable>
          </task>
        </taskFlow>
      </job>